{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de rede neural\n",
    "\n",
    "Utilizando a base v5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as plot\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "params = { \n",
    "    'axes.labelsize': \"large\",\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'legend.fontsize': 20,\n",
    "    'figure.dpi': 150,\n",
    "    'figure.figsize': [10, 6]\n",
    "}\n",
    "plot.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>SmallFamily</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_C</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>Ticket_7</th>\n",
       "      <th>Ticket_F</th>\n",
       "      <th>Ticket_6</th>\n",
       "      <th>Ticket_4</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>1</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Title_Mr  Sex     Age  Title_Mrs      Fare  Pclass_3  Cabin_T  SmallFamily  \\\n",
       "0         1    1  0.2750          0  0.014151         1        1            1   \n",
       "1         0    0  0.4750          1  0.139136         0        0            1   \n",
       "2         0    0  0.3250          0  0.015469         1        1            0   \n",
       "3         0    0  0.4375          1  0.103644         0        0            1   \n",
       "4         1    1  0.4375          0  0.015713         1        1            0   \n",
       "\n",
       "   Title_Miss  Pclass_1  ...  Ticket_C  Cabin_A  Cabin_F  Title_Royalty  \\\n",
       "0           0         0  ...         0        0        0              0   \n",
       "1           0         1  ...         0        0        0              0   \n",
       "2           1         0  ...         0        0        0              0   \n",
       "3           0         1  ...         0        0        0              0   \n",
       "4           0         0  ...         0        0        0              0   \n",
       "\n",
       "   Ticket_7  Ticket_F  Ticket_6  Ticket_4  PassengerId  Survived  \n",
       "0         0         0         0         0            1         0  \n",
       "1         0         0         0         0            2         1  \n",
       "2         0         0         0         0            3         1  \n",
       "3         0         0         0         0            4         1  \n",
       "4         0         0         0         0            5         0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino = pd.read_csv('https://raw.githubusercontent.com/SalatielBairros/kaggle-titanic/main/data/processed_v5_1/train.csv')\n",
    "teste = pd.read_csv('https://raw.githubusercontent.com/SalatielBairros/kaggle-titanic/main/data/processed_v5_1/test.csv')\n",
    "\n",
    "X_treino = treino.drop(columns=['PassengerId','Survived', 'Fare'])\n",
    "y_treino = treino['Survived']\n",
    "X_teste = teste.drop(columns=['PassengerId', 'Fare'])\n",
    "validation_passanger_ids = teste['PassengerId']\n",
    "\n",
    "treino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title_Mr', 'Sex', 'Age', 'Title_Mrs', 'Pclass_3', 'Cabin_T',\n",
       "       'SmallFamily', 'Title_Miss', 'Pclass_1', 'FamilySize', 'LargeFamily',\n",
       "       'Ticket_1', 'SibSp', 'Singleton', 'Ticket_3', 'Pclass_2',\n",
       "       'Title_Master', 'Title_Officer', 'Parch', 'Embarked_C', 'Ticket_2',\n",
       "       'Cabin_E', 'Embarked_S', 'Cabin_D', 'Embarked_Q', 'Cabin_C', 'Ticket_S',\n",
       "       'Cabin_B', 'Ticket_P', 'Ticket_A', 'Ticket_C', 'Cabin_A', 'Cabin_F',\n",
       "       'Title_Royalty', 'Ticket_7', 'Ticket_F', 'Ticket_6', 'Ticket_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep = ['Title_Mr', 'Sex', 'Age', 'Title_Mrs', 'Pclass_3', 'Cabin_T',\n",
    "#        'SmallFamily', 'Title_Miss', 'Pclass_1', 'FamilySize', 'LargeFamily',\n",
    "#        'Ticket_1', 'SibSp', 'Singleton', 'Ticket_3', 'Pclass_2',\n",
    "#        'Title_Master', 'Title_Officer', 'Parch', 'Embarked_C', 'Ticket_2',\n",
    "#        'Embarked_S','Cabin_B', 'Ticket_P']\n",
    "keep = X_treino.columns\n",
    "new_x_treino = X_treino[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_162 (Dense)           (None, 16)                624       \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 24)                408       \n",
      "                                                                 \n",
      " dense_164 (Dense)           (None, 16)                400       \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 16)                272       \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 8)                 72        \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_168 (Dense)           (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,953\n",
      "Trainable params: 1,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=38, units=16, kernel_initializer=\"GlorotUniform\"))\n",
    "classifier.add(Dense(activation=\"relu\", units=24, kernel_initializer=\"GlorotUniform\", use_bias=True))\n",
    "classifier.add(Dense(activation=\"relu\", units=16, kernel_initializer=\"GlorotUniform\"))\n",
    "classifier.add(Dense(activation=\"relu\", units=16, kernel_initializer=\"GlorotUniform\", use_bias=True))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=8, kernel_initializer=\"GlorotUniform\"))\n",
    "classifier.add(Dense(activation=\"relu\", units=8, kernel_initializer=\"GlorotUniform\"))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=4, kernel_initializer=\"GlorotUniform\"))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"GlorotUniform\"))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = y_treino.values\n",
    "features = new_x_treino.values\n",
    "\n",
    "x_teste_features = X_teste[keep].values\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "72/72 [==============================] - 1s 3ms/step - loss: 0.7277 - accuracy: 0.3933 - val_loss: 0.7011 - val_accuracy: 0.3575\n",
      "Epoch 2/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6922 - accuracy: 0.5070 - val_loss: 0.6702 - val_accuracy: 0.6425\n",
      "Epoch 3/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.6695 - accuracy: 0.6011 - val_loss: 0.6376 - val_accuracy: 0.6425\n",
      "Epoch 4/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6728 - val_loss: 0.5760 - val_accuracy: 0.7877\n",
      "Epoch 5/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.7261 - val_loss: 0.5138 - val_accuracy: 0.8212\n",
      "Epoch 6/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.7331 - val_loss: 0.4944 - val_accuracy: 0.8380\n",
      "Epoch 7/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.7739 - val_loss: 0.4693 - val_accuracy: 0.8547\n",
      "Epoch 8/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.7683 - val_loss: 0.4499 - val_accuracy: 0.8492\n",
      "Epoch 9/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.7851 - val_loss: 0.4385 - val_accuracy: 0.8492\n",
      "Epoch 10/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7584 - val_loss: 0.4320 - val_accuracy: 0.8547\n",
      "Epoch 11/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7612 - val_loss: 0.4269 - val_accuracy: 0.8436\n",
      "Epoch 12/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.7640 - val_loss: 0.4269 - val_accuracy: 0.8492\n",
      "Epoch 13/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7837 - val_loss: 0.4220 - val_accuracy: 0.8492\n",
      "Epoch 14/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7907 - val_loss: 0.4200 - val_accuracy: 0.8380\n",
      "Epoch 15/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7851 - val_loss: 0.4145 - val_accuracy: 0.8492\n",
      "Epoch 16/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7767 - val_loss: 0.4126 - val_accuracy: 0.8492\n",
      "Epoch 17/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7753 - val_loss: 0.4132 - val_accuracy: 0.8436\n",
      "Epoch 18/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7963 - val_loss: 0.4010 - val_accuracy: 0.8547\n",
      "Epoch 19/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7654 - val_loss: 0.4010 - val_accuracy: 0.8547\n",
      "Epoch 20/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7935 - val_loss: 0.4087 - val_accuracy: 0.8547\n",
      "Epoch 21/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7907 - val_loss: 0.3997 - val_accuracy: 0.8547\n",
      "Epoch 22/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7837 - val_loss: 0.4037 - val_accuracy: 0.8603\n",
      "Epoch 23/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7725 - val_loss: 0.4130 - val_accuracy: 0.8380\n",
      "Epoch 24/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8090 - val_loss: 0.3942 - val_accuracy: 0.8603\n",
      "Epoch 25/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7949 - val_loss: 0.3922 - val_accuracy: 0.8659\n",
      "Epoch 26/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.8048 - val_loss: 0.4011 - val_accuracy: 0.8603\n",
      "Epoch 27/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.8062 - val_loss: 0.4011 - val_accuracy: 0.8547\n",
      "Epoch 28/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.8272 - val_loss: 0.4031 - val_accuracy: 0.8492\n",
      "Epoch 29/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.8048 - val_loss: 0.4050 - val_accuracy: 0.8492\n",
      "Epoch 30/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8216 - val_loss: 0.4044 - val_accuracy: 0.8492\n",
      "Epoch 31/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8258 - val_loss: 0.4006 - val_accuracy: 0.8547\n",
      "Epoch 32/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.8090 - val_loss: 0.3985 - val_accuracy: 0.8547\n",
      "Epoch 33/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8062 - val_loss: 0.3987 - val_accuracy: 0.8547\n",
      "Epoch 34/200\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.8034 - val_loss: 0.4097 - val_accuracy: 0.8436\n",
      "Epoch 35/200\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8202 - val_loss: 0.4070 - val_accuracy: 0.8492\n",
      "Epoch 35: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(features, target, batch_size = 10, epochs  = 200, validation_split=0.2, verbose = 1, shuffle=True, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(x_teste_features).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame(Y_pred, validation_passanger_ids, columns = ['Survived'])\n",
    "predictions = solution['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81       260\n",
      "           1       0.70      0.68      0.69       158\n",
      "\n",
      "    accuracy                           0.77       418\n",
      "   macro avg       0.75      0.75      0.75       418\n",
      "weighted avg       0.77      0.77      0.77       418\n",
      "\n",
      "0.7679425837320574\n"
     ]
    }
   ],
   "source": [
    "gt = pd.read_csv('../../data/original/ground_truth.csv')\n",
    "print(classification_report(gt['Survived'], predictions))\n",
    "print(accuracy_score(gt['Survived'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('../../data/nn_models/modelo_equivalente_nn.h5')\n",
    "classifier.save_weights('../../data/nn_models/w_modelo_equivalente_nn.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salat\\AppData\\Local\\Temp/ipykernel_78732/2040922932.py:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salat\\AppData\\Local\\Temp/ipykernel_78732/2040922932.py:171: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimator = KerasClassifier(build_fn = create_baseline, epochs = 20, batch_size = 10, verbose = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.6152\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 0.6461\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 0s 914us/step - loss: 0.5552 - accuracy: 0.7107\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.7809\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 0s 971us/step - loss: 0.4946 - accuracy: 0.7879\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 0s 916us/step - loss: 0.4815 - accuracy: 0.8048\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 0s 873us/step - loss: 0.4586 - accuracy: 0.8160\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 0s 837us/step - loss: 0.4512 - accuracy: 0.8118\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 0s 903us/step - loss: 0.4335 - accuracy: 0.8301\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.4271 - accuracy: 0.8413\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 0s 797us/step - loss: 0.4283 - accuracy: 0.8385\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.4148 - accuracy: 0.8441\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4109 - accuracy: 0.8371\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8385\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 0s 998us/step - loss: 0.3883 - accuracy: 0.8497\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8497\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 0s 987us/step - loss: 0.4019 - accuracy: 0.8371\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3941 - accuracy: 0.8287\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 0s 948us/step - loss: 0.3872 - accuracy: 0.8343\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8343\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.3652 - accuracy: 0.8380\n",
      "Epoch 1/20\n",
      "72/72 [==============================] - 1s 1ms/step - loss: 0.6176 - accuracy: 0.6788\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7237\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.7826\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.8022\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 0s 919us/step - loss: 0.4328 - accuracy: 0.8191\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8177\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 0s 905us/step - loss: 0.4143 - accuracy: 0.8107\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.3920 - accuracy: 0.8331\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 0s 847us/step - loss: 0.3828 - accuracy: 0.8373\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8275\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8443\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.3705 - accuracy: 0.8373\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 0s 906us/step - loss: 0.3756 - accuracy: 0.8401\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 0s 914us/step - loss: 0.3557 - accuracy: 0.8555\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8555\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.3586 - accuracy: 0.8415\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8345\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8499\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.3464 - accuracy: 0.8597\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 0s 913us/step - loss: 0.3524 - accuracy: 0.8443\n",
      "18/18 [==============================] - 0s 479us/step - loss: 0.4558 - accuracy: 0.8371\n",
      "Epoch 1/20\n",
      "72/72 [==============================] - 0s 918us/step - loss: 0.6723 - accuracy: 0.6059\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6145 - accuracy: 0.7475\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.7742\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 0s 932us/step - loss: 0.4849 - accuracy: 0.7980\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8219\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8303\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.8317\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8331\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 0s 902us/step - loss: 0.3962 - accuracy: 0.8415\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 0s 927us/step - loss: 0.4045 - accuracy: 0.8331\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8345\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3834 - accuracy: 0.8429\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8499\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.8415\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 0s 802us/step - loss: 0.3983 - accuracy: 0.8429\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 0s 904us/step - loss: 0.3808 - accuracy: 0.8555\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 0s 931us/step - loss: 0.3876 - accuracy: 0.8513\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3740 - accuracy: 0.8443\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 0s 801us/step - loss: 0.3769 - accuracy: 0.8471\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 0s 790us/step - loss: 0.3775 - accuracy: 0.8513\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.3515 - accuracy: 0.8483\n",
      "Epoch 1/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8006 - accuracy: 0.4025\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.5680\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6662\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5446 - accuracy: 0.7279\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7784\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7980\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.8289\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8415\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4190 - accuracy: 0.8247\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8275\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.4015 - accuracy: 0.8555\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3976 - accuracy: 0.8541\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 0s 910us/step - loss: 0.3987 - accuracy: 0.8401\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 0s 971us/step - loss: 0.3749 - accuracy: 0.8527\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.3940 - accuracy: 0.8499\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8527\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 0s 931us/step - loss: 0.3776 - accuracy: 0.8555\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8612\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8569\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 0s 914us/step - loss: 0.3843 - accuracy: 0.8555\n",
      "18/18 [==============================] - 0s 470us/step - loss: 0.3892 - accuracy: 0.8427\n",
      "Epoch 1/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.6800 - accuracy: 0.5610\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 0s 919us/step - loss: 0.5869 - accuracy: 0.7195\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.7447\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.8065\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.8261\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.8079\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 0s 972us/step - loss: 0.4280 - accuracy: 0.8331\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8429\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8359\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.4136 - accuracy: 0.8317\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.4031 - accuracy: 0.8331\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 0s 905us/step - loss: 0.3963 - accuracy: 0.8387\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 0s 915us/step - loss: 0.3953 - accuracy: 0.8471\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 0s 976us/step - loss: 0.3950 - accuracy: 0.8415\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 0s 895us/step - loss: 0.4017 - accuracy: 0.8387\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 0s 909us/step - loss: 0.3979 - accuracy: 0.8471\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 0s 907us/step - loss: 0.4005 - accuracy: 0.8457\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 0s 901us/step - loss: 0.3803 - accuracy: 0.8527\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 0s 899us/step - loss: 0.3888 - accuracy: 0.8429\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 0s 922us/step - loss: 0.3986 - accuracy: 0.8359\n",
      "18/18 [==============================] - 0s 470us/step - loss: 0.3159 - accuracy: 0.8596\n",
      "Results: 84.51% (0.82%)\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.6790\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7576\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 0s 913us/step - loss: 0.4585 - accuracy: 0.7957\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.8070\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 0s 899us/step - loss: 0.4172 - accuracy: 0.8204\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8350\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 0s 904us/step - loss: 0.4103 - accuracy: 0.8339\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 0s 919us/step - loss: 0.3958 - accuracy: 0.8496\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 0s 1000us/step - loss: 0.3890 - accuracy: 0.8395\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8339\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8485\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 0s 936us/step - loss: 0.3842 - accuracy: 0.8485\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8418\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 0s 993us/step - loss: 0.3752 - accuracy: 0.8485\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 0s 930us/step - loss: 0.3623 - accuracy: 0.8541\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 0s 986us/step - loss: 0.3685 - accuracy: 0.8485\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8361\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 0s 993us/step - loss: 0.3747 - accuracy: 0.8530\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8541\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86       260\n",
      "           1       0.81      0.66      0.72       158\n",
      "\n",
      "    accuracy                           0.81       418\n",
      "   macro avg       0.81      0.78      0.79       418\n",
      "weighted avg       0.81      0.81      0.81       418\n",
      "\n",
      "0.8110047846889952\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "#  Libraries\n",
    "####################################\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "# Data processing, metrics and modeling\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# Reproductibility\n",
    "from numpy.random import seed\n",
    "seed(1002)\n",
    "import tensorflow \n",
    "\n",
    "tensorflow.random.set_seed(1002)\n",
    "# import set_random_seed\n",
    "# set_random_seed(1002)\n",
    "\n",
    "####################################\n",
    "# Importing data and merging\n",
    "####################################\n",
    "\n",
    "# Reading dataset\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/SalatielBairros/kaggle-titanic/main/data/original/train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/SalatielBairros/kaggle-titanic/main/data/original/test.csv\")\n",
    "\n",
    "# Adding a column in each dataset before merging\n",
    "train['Type'] = 'train'\n",
    "test['Type'] = 'test'\n",
    "\n",
    "# Merging train and test\n",
    "data = train.append(test)\n",
    "\n",
    "####################################\n",
    "# Missing values and new features\n",
    "####################################\n",
    "\n",
    "# Title\n",
    "data['Title'] = data['Name']\n",
    "\n",
    "# Cleaning name and extracting Title\n",
    "for name_string in data['Name']:\n",
    "    data['Title'] = data['Name'].str.extract('([A-Za-z]+)\\.', expand=True)\n",
    "    \n",
    "# Replacing rare titles \n",
    "mapping = {'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs', 'Major': 'Other', \n",
    "           'Col': 'Other', 'Dr' : 'Other', 'Rev' : 'Other', 'Capt': 'Other', \n",
    "           'Jonkheer': 'Royal', 'Sir': 'Royal', 'Lady': 'Royal', \n",
    "           'Don': 'Royal', 'Countess': 'Royal', 'Dona': 'Royal'}\n",
    "           \n",
    "data.replace({'Title': mapping}, inplace=True)\n",
    "titles = ['Miss', 'Mr', 'Mrs', 'Royal', 'Other', 'Master']\n",
    "\n",
    "# Replacing missing age by median/title \n",
    "for title in titles:\n",
    "    age_to_impute = data.groupby('Title')['Age'].median()[titles.index(title)]\n",
    "    data.loc[(data['Age'].isnull()) & (data['Title'] == title), 'Age'] = age_to_impute\n",
    "    \n",
    "# New feature : Family_size\n",
    "data['Family_Size'] = data['Parch'] + data['SibSp'] + 1\n",
    "data.loc[:,'FsizeD'] = 'Alone'\n",
    "data.loc[(data['Family_Size'] > 1),'FsizeD'] = 'Small'\n",
    "data.loc[(data['Family_Size'] > 4),'FsizeD'] = 'Big'\n",
    "\n",
    "# Replacing missing Fare by median/Pclass \n",
    "fa = data[data[\"Pclass\"] == 3]\n",
    "data['Fare'].fillna(fa['Fare'].median(), inplace = True)\n",
    "\n",
    "#  New feature : Child\n",
    "data.loc[:,'Child'] = 1\n",
    "data.loc[(data['Age'] >= 18),'Child'] =0\n",
    "\n",
    "# New feature : Family Survival (https://www.kaggle.com/konstantinmasich/titanic-0-82-0-83)\n",
    "data['Last_Name'] = data['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "DEFAULT_SURVIVAL_VALUE = 0.5\n",
    "\n",
    "data['Family_Survival'] = DEFAULT_SURVIVAL_VALUE\n",
    "for grp, grp_df in data[['Survived','Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "                               \n",
    "    if (len(grp_df) != 1):\n",
    "        # A Family group is found.\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            smax = grp_df.drop(ind)['Survived'].max()\n",
    "            smin = grp_df.drop(ind)['Survived'].min()\n",
    "            passID = row['PassengerId']\n",
    "            if (smax == 1.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "            elif (smin == 0.0):\n",
    "                data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                \n",
    "for _, grp_df in data.groupby('Ticket'):\n",
    "    if (len(grp_df) != 1):\n",
    "        for ind, row in grp_df.iterrows():\n",
    "            if (row['Family_Survival'] == 0) | (row['Family_Survival']== 0.5):\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 1\n",
    "                elif (smin == 0.0):\n",
    "                    data.loc[data['PassengerId'] == passID, 'Family_Survival'] = 0\n",
    "                    \n",
    "####################################\n",
    "# Encoding and pre-modeling\n",
    "####################################                  \n",
    "\n",
    "# dropping useless features\n",
    "data = data.drop(columns = ['Age','Cabin','Embarked','Name','Last_Name',\n",
    "                            'Parch', 'SibSp','Ticket', 'Family_Size'])\n",
    "\n",
    "# Encoding features\n",
    "target_col = [\"Survived\"]\n",
    "id_dataset = [\"Type\"]\n",
    "cat_cols   = data.nunique()[data.nunique() < 12].keys().tolist()\n",
    "cat_cols   = [x for x in cat_cols ]\n",
    "# numerical columns\n",
    "num_cols   = [x for x in data.columns if x not in cat_cols + target_col + id_dataset]\n",
    "# Binary columns with 2 values\n",
    "bin_cols   = data.nunique()[data.nunique() == 2].keys().tolist()\n",
    "# Columns more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "# Label encoding Binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    data[i] = le.fit_transform(data[i])\n",
    "# Duplicating columns for multi value columns\n",
    "data = pd.get_dummies(data = data,columns = multi_cols )\n",
    "# Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(data[num_cols])\n",
    "scaled = pd.DataFrame(scaled,columns = num_cols)\n",
    "# dropping original values merging scaled values for numerical columns\n",
    "df_data_og = data.copy()\n",
    "data = data.drop(columns = num_cols,axis = 1)\n",
    "data = data.merge(scaled,left_index = True,right_index = True,how = \"left\")\n",
    "data = data.drop(columns = ['PassengerId'],axis = 1)\n",
    "\n",
    "# Target = 1st column\n",
    "cols = data.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('Survived')))\n",
    "data = data.reindex(columns= cols)\n",
    "\n",
    "# Cutting train and test\n",
    "train = data[data['Type'] == 1].drop(columns = ['Type'])\n",
    "test = data[data['Type'] == 0].drop(columns = ['Type'])\n",
    "\n",
    "# X and Y\n",
    "X_train = train.iloc[:, 1:20].values\n",
    "y_train = train.iloc[:,0].values\n",
    "\n",
    "####################################\n",
    "# Keras - Neural Networks\n",
    "####################################\n",
    "\n",
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim = 18, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn = create_baseline, epochs = 20, batch_size = 10, verbose = 1)\n",
    "# kfold = StratifiedKFold(n_splits = 5, random_state = 42, shuffle = False)\n",
    "kfold = StratifiedKFold(n_splits = 5, shuffle = False)\n",
    "results = cross_val_score(estimator, X_train, y_train, cv = kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "\n",
    "# X Test\n",
    "X_test = test.iloc[:, 1:20].values\n",
    "\n",
    "estimator.fit(X_train, y_train, epochs = 20, batch_size = 10)\n",
    "\n",
    "# Predicting y_test\n",
    "prediction = estimator.predict(X_test).tolist()\n",
    "\n",
    "# List to series\n",
    "data_check =  pd.read_csv(\"https://raw.githubusercontent.com/SalatielBairros/kaggle-titanic/main/data/original/test.csv\")\n",
    "se = pd.Series(prediction)\n",
    "# Creating new column of predictions in data_check dataframe\n",
    "data_check['check'] = se\n",
    "data_check['check'] = data_check['check'].str.get(0)\n",
    "\n",
    "series = []\n",
    "for val in data_check.check:\n",
    "    if val >= 0.5:\n",
    "        series.append(1)\n",
    "    else:\n",
    "        series.append(0)\n",
    "data_check['final'] = series\n",
    "\n",
    "match = 0\n",
    "nomatch = 0\n",
    "for val in data_check.values:\n",
    "    if val[1] == val[3]:\n",
    "        match = match +1\n",
    "    else:\n",
    "        nomatch = nomatch +1\n",
    "\n",
    "####################################\n",
    "# Submission\n",
    "#################################### \n",
    "\n",
    "temp = pd.DataFrame(pd.read_csv(\"https://raw.githubusercontent.com/SalatielBairros/kaggle-titanic/main/data/original/test.csv\")['PassengerId'])\n",
    "temp['Survived'] = data_check['final']\n",
    "\n",
    "predictions = data_check['final'].tolist()\n",
    "gt = pd.read_csv('../../data/original/ground_truth.csv')\n",
    "print(classification_report(gt['Survived'], predictions))\n",
    "print(accuracy_score(gt['Survived'], predictions))\n",
    "\n",
    "temp.to_csv(\"../../data/submissions/keras_ex_nn.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Type</th>\n",
       "      <th>Child</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "      <th>Title_Royal</th>\n",
       "      <th>FsizeD_Alone</th>\n",
       "      <th>FsizeD_Big</th>\n",
       "      <th>FsizeD_Small</th>\n",
       "      <th>Family_Survival_0.0</th>\n",
       "      <th>Family_Survival_0.5</th>\n",
       "      <th>Family_Survival_1.0</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.503176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.503176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.490126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.392009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.189974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.493509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Sex  Type  Child  Pclass_1  Pclass_2  Pclass_3  Title_Master  \\\n",
       "0           0    1     1      0         0         0         1             0   \n",
       "0           2    1     0      0         0         0         1             0   \n",
       "1           1    0     1      0         1         0         0             0   \n",
       "1           2    0     0      0         0         0         1             0   \n",
       "2           1    0     1      0         0         0         1             0   \n",
       "..        ...  ...   ...    ...       ...       ...       ...           ...   \n",
       "886         0    1     1      0         0         1         0             0   \n",
       "887         1    0     1      0         1         0         0             0   \n",
       "888         0    0     1      1         0         0         1             0   \n",
       "889         1    1     1      0         1         0         0             0   \n",
       "890         0    1     1      0         0         0         1             0   \n",
       "\n",
       "     Title_Miss  Title_Mr  Title_Mrs  Title_Other  Title_Royal  FsizeD_Alone  \\\n",
       "0             0         1          0            0            0             0   \n",
       "0             0         1          0            0            0             1   \n",
       "1             0         0          1            0            0             0   \n",
       "1             0         0          1            0            0             0   \n",
       "2             1         0          0            0            0             1   \n",
       "..          ...       ...        ...          ...          ...           ...   \n",
       "886           0         0          0            1            0             1   \n",
       "887           1         0          0            0            0             1   \n",
       "888           1         0          0            0            0             0   \n",
       "889           0         1          0            0            0             1   \n",
       "890           0         1          0            0            0             1   \n",
       "\n",
       "     FsizeD_Big  FsizeD_Small  Family_Survival_0.0  Family_Survival_0.5  \\\n",
       "0             0             1                    0                    1   \n",
       "0             0             0                    0                    1   \n",
       "1             0             1                    0                    1   \n",
       "1             0             1                    0                    1   \n",
       "2             0             0                    0                    1   \n",
       "..          ...           ...                  ...                  ...   \n",
       "886           0             0                    0                    1   \n",
       "887           0             0                    0                    1   \n",
       "888           0             1                    1                    0   \n",
       "889           0             0                    0                    1   \n",
       "890           0             0                    0                    1   \n",
       "\n",
       "     Family_Survival_1.0      Fare  \n",
       "0                      0 -0.503176  \n",
       "0                      0 -0.503176  \n",
       "1                      0  0.734809  \n",
       "1                      0  0.734809  \n",
       "2                      0 -0.490126  \n",
       "..                   ...       ...  \n",
       "886                    0 -0.392009  \n",
       "887                    0 -0.063340  \n",
       "888                    0 -0.189974  \n",
       "889                    0 -0.063340  \n",
       "890                    0 -0.493509  \n",
       "\n",
       "[1309 rows x 20 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d8406cfaedcdf0eaa4a44a61b5b4d06f47db5698936240ac59b59333d280fd9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
